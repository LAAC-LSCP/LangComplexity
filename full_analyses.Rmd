---
title: "Full CR analyses"
author: "NK & AC"
date: "2/23/2021"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse) # I wasn't able to run this package from groundhog in Windows
library(car) # I wasn't able to run this package from groundhog in Windows

library(groundhog)
groundhog.day="2021-02-23"
pkgs=c('tidyverse','ggplot2','gvlma','car','RCurl','plyr','readxl','knitr',
       'rmarkdown')
groundhog.library(pkgs, groundhog.day)


# Seed for random number generation
set.seed(22)

#document session info
capture.output(sessionInfo(),file="lastknit_session_info.txt")

opts_chunk$set(echo = TRUE)
```

## Read in data

```{r read-in}

# Generate canonical proportion for data from .eaf
  # French Solomon Tsimane
raw_eaf_data<- read_excel("RawData/Raw_data_full.xlsx")
raw_eaf_data$Subtier_type<-NA
raw_eaf_data$Subtier_type[grep("vcm",raw_eaf_data$Subtier)]<-"vcm"
raw_eaf_data$clean_ChildID <- gsub("_period.*","",gsub("_._period.*","",raw_eaf_data$Filename))
raw_eaf_data$clean_ChildID <- gsub("random.*","",raw_eaf_data$clean_ChildID)
raw_eaf_data$clean_ChildID <- gsub("periodic.*","",raw_eaf_data$clean_ChildID)
raw_eaf_data$clean_ChildID <- gsub("_LD.*","",raw_eaf_data$clean_ChildID)

vcm_tab <- table(raw_eaf_data$clean_ChildID[raw_eaf_data$Subtier_type=="vcm" & raw_eaf_data$Tier=="CHI"],raw_eaf_data$Type[raw_eaf_data$Subtier_type=="vcm" & raw_eaf_data$Tier=="CHI"])
vcm_tab_chi_eaf <- vcm_tab[,"C"]/(vcm_tab[,"C"]+vcm_tab[,"N"])

# Generate canonical proportion for data from cychosz
  #contains: Casillas-Yeli  Cychosz Seedlings    Tsimane    Warlaumont 
raw_cychosz_data<- read_csv("Data/meta_answers_global_crossling_9-20.csv")
raw_cychosz_data$unique_child_ID <- paste(raw_cychosz_data$language,raw_cychosz_data$child_ID)

vcm_tab <- table(raw_cychosz_data$unique_child_ID,raw_cychosz_data$Answer)
vcm_tab_chi_cychosz <- vcm_tab[,"Canonical"]/(vcm_tab[,"Canonical"]+vcm_tab[,"Non-canonical"])

# Generate canonical proportion for data from zooniverse #TODO
  #contains: Yélî & Tsimane

other_data<- read_excel("Data/CR_by_child-updated_21_01.xlsx")
other_data_tsi<- read_excel("Data/CR_by_child_tsi.xlsx")

# we'll use the best and most data we can:
#- Yélî will come from zooniverse-other DONE
#- Tsimane will come from zooniverse-tsi DONE
#- French Solomon from eaf DONE
#- the rest of the corpora will come from cychosz TODO

#also, we want to be able to merge our CPs into other_data because other_data has age of the child

best_data=other_data[other_data$corpus %in% c("Yélî"),]

#next, add tsi kids
#best_data <- merge(best_data,other_data_tsi, by="ChildID", all=T)
best_data <- rbind.fill(best_data,other_data_tsi) #it merge datasets smoothly in this way


#next, add French & Solomon + Tsimane
#to this end, first we need to add the CPs
vcm_tab_chi_eaf2=data.frame(cbind(vcm_tab_chi_eaf,names(vcm_tab_chi_eaf)))
colnames(vcm_tab_chi_eaf2)<-c("CR","ChildID") #renamed column to ChildID for consistency
vcm_tab_chi_eaf2$CR <- as.numeric(as.character(vcm_tab_chi_eaf2$CR))

#subset to French & Solomon 
other_data_fs <- subset(other_data, corpus %in% c("French","Solomon"))
other_data_fs$CR <- NULL #what if we get rid of CR column here so in the following merging we could work with R calculated data
other_data_fs$ChildID <-gsub("_period.*","",gsub("_._period.*","",other_data_fs$ChildID))
other_data_fs$ChildID <- gsub("random.*","",other_data_fs$ChildID)
other_data_fs$ChildID <- gsub("periodic.*","",other_data_fs$ChildID)
other_data_fs$ChildID <- gsub("_LD.*","",other_data_fs$ChildID)

other_data_fs <- merge(other_data_fs,vcm_tab_chi_eaf2,by="ChildID",all=T)

#and next we add French & Solomon 
#best_data <- merge(best_data,other_data_fs,by="ChildID",all=T) #this way doesn't combine datasets properly
best_data <- rbind.fill(best_data,other_data_fs) #this generates different number of entries every time?!

#stopped here!
# what is missing is:
# fill in age for 2 French children who are missing age, we can tell the age from the file name:
# FRH_020712 is 2 years 7 months 12 days -DONE
#GOG_000302 3 months 2 days - CP is 0, Should we eliminate this child in this case?


##CLEANING
best_data$syl_comp <- factor(best_data$`Syllable complexity`, levels=c("Low","Moderate","High"))
best_data$lang <- as.factor(best_data$Language)

best_data$age <-  as.numeric(coalesce(best_data$`Age in months`, best_data$Age)) #combining age of both datasets
#NB we cannot filter children by age yet as some rows misses values that we are going to solver in next steps

#Assigning values for children uploaded from OSF
best_data['92', c('lang', 'corpus')] <- 'French'
best_data['92', 'C_count'] <- '21'
best_data['92', 'V_count'] <- '17'
best_data['92', 'syl_comp'] <- 'High'
best_data['92', 'age'] <- '31.4'

best_data[c(95:101), c('lang', 'corpus')] = "Tsimane"
best_data[c(95:101), 'C_count'] = "25"
best_data[c(95:101), 'V_count'] = "18"
best_data[c(95:101), 'syl_comp'] <- 'Moderate'
best_data[c(95:96, 101), 'Gender'] <- 'F'
best_data[c(97:100), 'Gender'] <- 'M'

best_data[c(95:96), 'age'] <- '32' 
best_data[c(97:98), 'age'] <- '20' 
best_data[c(99:100), 'age'] <- '48' 
best_data['101', 'age'] <- '35' 

#and now we can filter them
best_data <- best_data %>% 
  filter(age <= 40) #after this your data reduces to 660 observations (<40) which you care about.
best_data$age <- as.numeric(best_data$age)

table(best_data$ChildID)[order(table(best_data$ChildID))]

best_data_clean=best_data[,c("age","lang","syl_comp","C_count","V_count","CR")]

```

#Phonetic properties

```{r read-in}

#DATASET WITH PHONETIC PROPERTIES ---------------------------------
#adding a file with phonetic data  
phon_data<- read_excel("C:/Users/Lenovo/Desktop/UNISI/ENS Traineeship/GIT/LangComplexity/Data/LAAC_Internship2020_Languages_upd.xlsx")

#MERGING TWO DATASETS TOGETHER
#select the columns to merge from the Languages file
phon_data <-phon_data %>% select(Language, Maddieson_C_inv, Maddieson_VQ_Inv, Maddieson_sylcomp)
phon_data$lang <- as.factor(phon_data$Language)
phon_data$Language <- NULL

#merge the selected columns into one dataset
mydata_sub<-merge(best_data_clean,phon_data, by="lang", all=T) #it leaves only 60 children, apparently because of the absence metada for some languages THIS WAY DUPLICATE SOME DATA 
mydata_sub <- dplyr::distinct(mydata_sub) # TO GET RID OF DUPLICATES
mydata_sub<-subset(mydata_sub, !is.na(CR)) #NA in CR are excluded -> 60 children

mydata_sub$Mad_syl_comp <- factor(mydata_sub$`Maddieson_sylcomp`, levels=c("Low","Moderate","High"))
mydata_sub$Mad_C <- factor(mydata_sub$`Maddieson_C_inv`, levels=c("Moderately Small","Average","Large"))
mydata_sub$Mad_VQ <-factor(mydata_sub$`Maddieson_VQ_Inv`, levels=c("Average","Large"))
mydata_sub$syl_comp <- NULL
mydata_sub$Maddieson_sylcomp <- NULL
mydata_sub$Maddieson_C_inv <- NULL
mydata_sub$Maddieson_VQ_Inv <- NULL


mydata_sub<-subset(mydata_sub, !is.na(CR)) #to get rid of empty CR entries

#correct some data issues
mydata_sub$age2=mydata_sub$age^2 #generate squared component
mydata_sub$age3=mydata_sub$age^3 #generate cubic component

mydata_sub<-subset(mydata_sub, !is.na(Mad_C)) #NA are excluded -> 51 children

```

#Plots
```{r read-in}
summary(mydata_sub)
dim(mydata_sub)

table(mydata_sub$lang) #shows N kids per language
table(mydata_sub$Mad_C,mydata_sub$lang) #Consonants
table(mydata_sub$Mad_VQ,mydata_sub$lang) #Vowels

#Histograms
hist(mydata_sub$CR,main="CR",xlab="CR") #quite normally distributed
###Consonants
hist(mydata_sub$CR[mydata_sub$Mad_C=="Moderately Small"],main="Consonants: Moderately Small",xlab="CR") 
hist(mydata_sub$CR[mydata_sub$Mad_C=="Average"],main="Consonants: Average",xlab="CR") 
###Vowels
hist(mydata_sub$CR[mydata_sub$Mad_VQ=="Average"],main="Vowels: Average",xlab="CR") 
hist(mydata_sub$CR[mydata_sub$Mad_VQ=="Large"],main="Vowels: Large",xlab="CR") 

#Plots
###Consonants - doesn't look impressive. The data quite unbalanced with average property leading
ggplot(mydata_sub,aes(x=CR,fill=Mad_C))+  
  geom_histogram(bins=20,color="black") + 
  facet_grid(.~Mad_C)  
###Vowels #looks a bit better, but still average property is leading
ggplot(mydata_sub,aes(x=CR,fill=Mad_VQ))+ 
  geom_histogram(bins=20,color="black") + 
  facet_grid(.~Mad_VQ) 


ggplot(mydata_sub, aes(x=age, y=CR, color=lang)) +
  labs(colour = "Languages", shape="Languages") +
  labs(x = "Age (months)")+
  labs(y = "CP")+
  geom_point()+
  # Add regression lines
  geom_smooth(method=lm,se=FALSE)


#More colorful diagrams :D
ggplot(mydata_sub,aes(x=CR,fill=C_count))+      #Consonants
  geom_histogram(bins=20,color="black") + 
  facet_grid(.~Mad_syl_comp)  


ggplot(mydata_sub,aes(x=CR,fill=V_count))+      #Vowels
  geom_histogram(bins=20,color="black") + 
  facet_grid(.~Mad_syl_comp) 



```

#Mean CR and Standard Deviation 

```{r read-in}

"Average CR"; mean(mydata_sub$CR) ; "Standard Deviation" ; sd(mydata_sub$CR)

#Consonants
"Average CR for Consonants: Moderately Small"; mean(mydata_sub$CR[mydata_sub$Mad_C == "Moderately Small"]) ; "Standard Deviation" ; sd(mydata_sub$CR[mydata_sub$Mad_C == "Moderately Small"])
"Average CR for Consonants: Average"; mean(mydata_sub$CR[mydata_sub$Mad_C == "Average"]) ; "Standard Deviation" ; sd(mydata_sub$CR[mydata_sub$Mad_C == "Average"])

boxplot(mydata_sub$CR~mydata_sub$Mad_C, main="Distribution of CP by Consonants", xlab="Consonants", ylab="CP")

#Vowels
"Average CR for Vowels: Average"; mean(mydata_sub$CR[mydata_sub$Mad_V == "Average"]) ; "Standard Deviation" ; sd(mydata_sub$CR[mydata_sub$Mad_V == "Average"])
"Average CR for Consonants: Large"; mean(mydata_sub$CR[mydata_sub$Mad_V == "Large"]) ; "Standard Deviation" ; sd(mydata_sub$CR[mydata_sub$Mad_V == "Large"])

boxplot(mydata_sub$CR~mydata_sub$Mad_V, main="Distribution of CP by Vowels", xlab="Vowels", ylab="CP")

```

#Pearson correlation

```{r read-in}
#Small vs. Average vs. Mod. Large Consonants -----------------------------------------

#Pearson's correlations for each Mad_C level
mydata_sub_S <- subset(mydata_sub,  Mad_C=="Moderately Small")
mydata_sub_A <- subset(mydata_sub,  Mad_C=="Average")

"Moderately Small Mad_C"; cor.test(mydata_sub_S$age,mydata_sub_S$CR) #0.8943559  
"Average Mad_C"; cor.test(mydata_sub_A$age,mydata_sub_A$CR) #0.468867 


#check assumptions
#Moderately Small Mad_C
lm_Small <- lm(mydata_sub_S$CR~mydata_sub_S$age)
par(mfrow=c(2,2))
plot(lm_Small, main="Moderately Small Mad_C")
#Average Mad_C
lm_Avg <- lm(mydata_sub_A$CR~mydata_sub_A$age)
par(mfrow=c(2,2))
plot(lm_Avg, main="Average Mad_C")  


#Small vs. Average
SvA <- subset(mydata_sub)
lm_SvA <- (lm(SvA$CR~SvA$age))
par(mfrow=c(2,2))
plot(lm_SvA, main="Small vs. Average")
"Small vs. Average"; anova(lm(SvA$CR~SvA$age*SvA$Mad_C))


#Average vs. Large Vowels -----------------------------------------

#Pearson's correlations for each Mad_V level
mydata_sub_Av <- subset(mydata_sub,  Mad_VQ=="Average")
mydata_sub_Lr <- subset(mydata_sub,  Mad_VQ=="Large")

"Average Mad_VQ"; cor.test(mydata_sub_Av$age,mydata_sub_Av$CR)  #0.4266869
"Large Mad_VQ"; cor.test(mydata_sub_Lr$age,mydata_sub_Lr$CR)  #0.7026577 


#check assumptions
#Average Mad_VQ
lm_Average <- lm(mydata_sub_Av$CR~mydata_sub_Av$age)
par(mfrow=c(2,2))
plot(lm_Average, main="Average Mad_VQ")  
#Large Mad_VQ 
lm_lrg <- lm(mydata_sub_Lr$CR~mydata_sub_Lr$age) #
par(mfrow=c(2,2))
plot(lm_lrg, main="Large Mad_VQ")  


#Average vs. Large
AvvLr <- subset(mydata_sub)
lm_AvvLr <- (lm(AvvLr$CR~AvvLr$age))
par(mfrow=c(2,2))
plot(lm_AvvLr, main="Average vs. Large")
"Average vs. Large"; anova(lm(AvvLr$CR~AvvLr$age*AvvLr$Mad_VQ))


#___________
attach(mydata_sub)
lm_data <- lm(CR ~ age +  Mad_syl_comp + Mad_VQ + Mad_C)
summary(lm_data)
summary(lm(age ~ CR +  Mad_syl_comp + Mad_VQ + Mad_C))

```


## TODO

2) figure out how to go from zooniverse to cr ??

4) create merged dataset with both data from eaf & data from zooniverse

- why do we have a separate spreadsheet for tsimane?
- are there missing children?

Comments:
* GOG_000302: CR value is 0. Should we omit this child in this case?
* C_count and V_count has are read as characters in best_data_clean. Are they factors?
* For Tsimane children (from OSF) now we have 2 recordings -> a mean value of them is needed
** rbind merges two datasets by chance and generates each time new number of data - We need to find a better solution
** My result is 51 children with all data (both phonetic and language complexity)
*We lost Mod. Large Consonants in Queschua in our data

